{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16809808",
   "metadata": {},
   "source": [
    "## # Lab | Comparing regression models\n",
    "\n",
    "\n",
    "For this lab, we will be using the same dataset we used in the previous labs. We recommend using the same notebook since you will be reusing the same variables you previous created and used in labs. \n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. In this final lab, we will model our data. Import sklearn `train_test_split` and separate the data.\n",
    "\n",
    "2. We will start with removing outliers, if you have not already done so.  We have discussed different methods to remove outliers. Use the one you feel more comfortable with, define a function for that. Use the function to remove the outliers and apply it to the dataframe.\n",
    "\n",
    "3. Create a copy of the dataframe for the data wrangling.\n",
    "\n",
    "4. Normalize the continuous variables. You can use any one method you want.\n",
    "\n",
    "5. Encode the categorical variables (See the hint below for encoding categorical data!!!)\n",
    "\n",
    "6. The time variable can be useful. Try to transform its data into a useful one. Hint: Day week and month as integers might be useful.\n",
    "\n",
    "7. Since the model will only accept numerical data, check and make sure that every column is numerical, if some are not, change it using encoding.\n",
    "\n",
    "\n",
    "## Hint for Categorical Variables\n",
    "\n",
    "You should deal with the categorical variables as shown below (for ordinal encoding, dummy code has been provided as well):\n",
    "Encoder Type | Column \n",
    "-----------------|-----------------\n",
    "One hot | state\n",
    "Ordinal | coverage\n",
    "Ordinal | employmentstatus\n",
    "Ordinal | location code\n",
    "One hot | marital status\n",
    "One hot | policy type\n",
    "One hot | policy\n",
    "One hot | renew offercustomer_df\n",
    "One hot | sales channel\n",
    "One hot | vehicle class\n",
    "Ordinal | vehicle size\n",
    "\n",
    "##### Dummy code\n",
    "data[\"coverage\"] = data[\"coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})\n",
    "\n",
    "given that column \"coverage\" in the dataframe \"data\" has three categories:\n",
    "\n",
    "\"basic\", \"extended\", and \"premium\" and values are to be represented in the same order.\n",
    "\n",
    "\n",
    "\n",
    "8. Try a simple linear regression with all the data to see whether we are getting good results.\n",
    "\n",
    "9. Great! Now define a function that takes a list of models and train (and tests) them so we can try a lot of them without repeating code.\n",
    "\n",
    "10. Use the function to check `LinearRegressor` and `KNeighborsRegressor`.\n",
    "\n",
    "11. You can check also the `MLPRegressor` for this task!\n",
    "\n",
    "12. Check and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd2f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e46238",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('we_fn_use_c_marketing_customer_value_analysis.csv')\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d025ce",
   "metadata": {},
   "source": [
    "#### 1. In this final lab, we will model our data. Import sklearn train_test_split and separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data):\n",
    "    data2 = data.copy()\n",
    "    numeric = data2.select_dtypes(np.number)\n",
    "    for col in numeric.columns:\n",
    "        if col != 'total_claim_amount':\n",
    "            iqr = np.percentile(data2[col],75) - np.percentile(data2[col],25)\n",
    "            upper_limit = np.percentile(data[col],75) + 1.5*iqr\n",
    "            lower_limit = np.percentile(data[col],25) - 1.5*iqr\n",
    "            data2 = data2[(data2[col] > lower_limit) & (data2[col] < upper_limit)]\n",
    "        return data2\n",
    "\n",
    "custumer_df = remove_outliers(customer_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f775700",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = customer_df.drop(['total_claim_amount'], axis=1)\n",
    "y = customer_df['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b83f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_discrete = X_train.select_dtypes(np.int64)\n",
    "X_train_continuous = X_train.select_dtypes([np.float64, np.datetime64])\n",
    "X_train_cat = X_train.select_dtypes(object)\n",
    "\n",
    "X_test_discrete = X_test.select_dtypes(np.int64)\n",
    "X_test_continuous = X_test.select_dtypes([np.float64, np.datetime64])\n",
    "X_test_cat = X_test.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_discrete['day']   = pd.to_datetime(X_train_continuous['effective_to_date']).dt.day\n",
    "X_train_discrete['month'] = pd.to_datetime(X_train_continuous['effective_to_date']).dt.month\n",
    "X_train_discrete['year']  = pd.to_datetime(X_train_continuous['effective_to_date']).dt.year\n",
    "X_train_continuous = X_train_continuous.drop(['effective_to_date'], axis=1)\n",
    "\n",
    "X_test_discrete['day']   = pd.to_datetime(X_test_continuous['effective_to_date']).dt.day\n",
    "X_test_discrete['month'] = pd.to_datetime(X_test_continuous['effective_to_date']).dt.month\n",
    "X_test_discrete['year']  = pd.to_datetime(X_test_continuous['effective_to_date']).dt.year\n",
    "X_test_continuous = X_test_continuous.drop(['effective_to_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49051ed",
   "metadata": {},
   "source": [
    "#### 2. We will start with removing outliers, if you have not already done so. We have discussed different methods to remove outliers. Use the one you feel more comfortable with, define a function for that. Use the function to remove the outliers and apply it to the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adacab00",
   "metadata": {},
   "source": [
    "#### 3. Create a copy of the dataframe for the data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = customer_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd58a4d",
   "metadata": {},
   "source": [
    "#### 4. Normalize the continuous variables. You can use any one method you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c47c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pT = PowerTransformer()\n",
    "pT.fit(X_train_continuous)\n",
    "\n",
    "X_train_continuous_trans_np = pT.transform(X_train_continuous)\n",
    "X_test_continuous_trans_np = pT.transform(X_test_continuous)\n",
    "\n",
    "\n",
    "X_train_continuous_trans = pd.DataFrame(X_train_continuous_trans_np, columns=X_train_continuous.columns,\n",
    "                                       index=X_train_continuous.index)\n",
    "X_test_continuous_trans = pd.DataFrame(X_test_continuous_trans_np, columns=X_test_continuous.columns,\n",
    "                                       index=X_test_continuous.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0345ad",
   "metadata": {},
   "source": [
    "#### 5. Encode the categorical variables (See the hint below for encoding categorical data!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(data):\n",
    "    data = data.drop(['customer'], axis=1)\n",
    "    return pd.get_dummies(data, drop_first=True)\n",
    "#                          columns=['state', 'marital_status',\n",
    "#                                   'policy_type', 'sales_channel',\n",
    "#                                   'vehicle_class'],\n",
    "#                          drop_first=True)\n",
    "\n",
    "X_train_cat_encoded = encode_categorical(X_train_cat)\n",
    "X_test_cat_encoded = encode_categorical(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8893b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pd.concat([X_train_discrete, X_train_continuous_trans, X_train_cat_encoded], axis=1)\n",
    "X_test_final = pd.concat([X_test_discrete, X_test_continuous_trans, X_test_cat_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db676b9",
   "metadata": {},
   "source": [
    "#### 6. The time variable can be useful. Try to transform its data into a useful one. Hint: Day week and month as integers might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93165458",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_final, y_train)\n",
    "print(f'Train score: {lm.score(X_train_final, y_train)}')\n",
    "print(f'Test score: {lm.score(X_test_final, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db868c",
   "metadata": {},
   "source": [
    "#### 7.  Since the model will only accept numerical data, check and make sure that every column is numerical, if some are not, change it using encoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6cf35e",
   "metadata": {},
   "source": [
    "#### 8. Try a simple linear regression with all the data to see whether we are getting good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5c261",
   "metadata": {},
   "source": [
    "#### 9.  Great! Now define a function that takes a list of models and train (and tests) them so we can try a lot of them without repeating code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(list_of_models, X_train, y_train):\n",
    "    for model in list_of_models:\n",
    "        model.fit(X_train, y_train)\n",
    "    return list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb48009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def evaluate_models(list_of_models, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for model in list_of_models:\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        train_scores.append(r2_score(y_train, y_train_pred))\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        test_scores.append(r2_score(y_test, y_test_pred))\n",
    "        \n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e4a31",
   "metadata": {},
   "source": [
    "#### 10. Use the function to check LinearRegressor and KNeighborsRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "list_of_models = [\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(n_neighbors=4)\n",
    "]\n",
    "\n",
    "list_of_trained_models = train_models(list_of_models, X_train_final, y_train)\n",
    "train_scores, test_scores = evaluate_models(list_of_trained_models,\n",
    "                                            X_train_final, y_train,\n",
    "                                            X_test_final, y_test)\n",
    "for i in range(len(list_of_models)):\n",
    "    print(f'Model: {list_of_trained_models[i]}')\n",
    "    print(f'    Train-Score: {train_scores[i]}')\n",
    "    print(f'    Test-Score:  {test_scores[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6218e31",
   "metadata": {},
   "source": [
    "#### 11. You can check also the MLPRegressor for this task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "list_of_models.append(MLPRegressor())\n",
    "\n",
    "list_of_trained_models = train_models(list_of_models, X_train_final, y_train)\n",
    "train_scores, test_scores = evaluate_models(list_of_trained_models,\n",
    "                                            X_train_final, y_train,\n",
    "                                            X_test_final, y_test)\n",
    "for i in range(len(list_of_models)):\n",
    "    print(f'Model: {list_of_trained_models[i]}')\n",
    "    print(f'    Train-Score: {train_scores[i]}')\n",
    "    print(f'    Test-Score:  {test_scores[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d6a64",
   "metadata": {},
   "source": [
    "#### 12. Check and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4827ec8",
   "metadata": {},
   "source": [
    "##### Best result on the training set is 0.76 using a linear regression model. The best result on the test set is 0.75, also with a linear regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
